{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TripletMultiTaskLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rytLzcI58tAN",
        "outputId": "97eac2bd-3c8b-4453-be78-0f83969754db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "hR0v-4ItTgtK",
        "outputId": "bf47211e-6500-48a6-ceb1-8793f8bdb4fa"
      },
      "source": [
        "pip install 'h5py==2.10.0' --force-reinstall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 4.0MB/s \n",
            "\u001b[?25hCollecting numpy>=1.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/03/c3526fb4e79a793498829ca570f2f868204ad9a8040afcd72d82a8f121db/numpy-1.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7MB 329kB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: lucid 0.3.10 requires umap-learn, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.2 has requirement gast==0.2.2, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: lucid 0.3.10 has requirement numpy<=1.19, but you'll have numpy 1.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, six, h5py\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0 numpy-1.21.0 six-1.16.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py",
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5uICw-oEi7C"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBjcLD56F1mt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859b7080-0f1b-4976-8f65-4f2bca06855a"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ7XBuWLFQMq"
      },
      "source": [
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8-sPpYSrIun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826ce9c1-c4c5-4b38-9da5-c58f38b74102"
      },
      "source": [
        "import keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOUR_CdnrL4V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "026eae70-3c1c-42c5-85ac-5d5937a3bdb3"
      },
      "source": [
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkI2GeX-979n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a549e654-179f-41ae-a92b-c10be8a09881"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import normalize\n",
        "from keras.layers import Input, Conv2D,  Dense, Flatten,MaxPooling2D, concatenate\n",
        "from keras.models import Model, Sequential\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from itertools import permutations, combinations, combinations_with_replacement\n",
        "from keras.layers import LSTM, Permute,Reshape\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import collections\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "from tensorflow.python.framework import dtypes\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "from tensorflow.python.keras import backend\n",
        "from tensorflow.python.keras.engine.base_layer import Layer\n",
        "# from tensorflow.python.keras.utils import control_flow_util\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import init_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import nn\n",
        "from tensorflow.python.util.tf_export import keras_export"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75WibHIVm1tU"
      },
      "source": [
        "# =============================================================================\n",
        "# MobilityAI\n",
        "# =============================================================================\n",
        "#MobilityAI data\n",
        "x = np.array([1,2,5,10,20])\n",
        "stl = np.array([0.5123,0.6667,0.7736,0.8423,0.9158])\n",
        "msens = np.array([0.8879,0.9237,0.9460,0.9544,0.9635])\n",
        "bmtl =np.array([0.8471,0.9388,0.9324,0.9391,0.9518])\n",
        "tmtl = np.array([0.9227,0.9298,0.9508,0.9541,0.9640])\n",
        "# example error bar values that vary with x-position\n",
        "error1 = np.array([0.1087,0.0889,0.0905,0.0512,0.0325])/np.sqrt(4)\n",
        "error2 = np.array([0.0505,0.0398,0.0315,0.0267,0.0270])/np.sqrt(4)\n",
        "error3 = np.array([0.0521,0.0458,0.0411,0.0475,0.0367])/np.sqrt(4)\n",
        "error4 = np.array([0.0605,0.0573,0.0238,0.0311,0.0251])/np.sqrt(4)\n",
        "men_means, men_std = (20, 35, 30, 35, 27), (2, 3, 4, 1, 2)\n",
        "women_means, women_std = (25, 32, 34, 20, 25), (3, 5, 2, 3, 3)\n",
        "ind = np.arange(len(men_means))  # the x locations for the groups\n",
        "width = 0.2  # the width of the bars\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "rects1 = ax.bar(ind - width*2, stl, width, yerr=error1,capsize=5,\n",
        "                label='STL')\n",
        "rects2 = ax.bar(ind - width, msens, width, yerr=error2,capsize=5,\n",
        "                label='MetaSense')\n",
        "rects3 = ax.bar(ind , bmtl, width, yerr=error3,capsize=5,\n",
        "                label='BMTL')\n",
        "rects4 = ax.bar(ind + width, tmtl, width, yerr=error4,capsize=5,\n",
        "                label='TMTL')\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Test Accuracy')\n",
        "ax.set_xlabel('Number of Data Windows')\n",
        "ax.set_title('MobilityAI')\n",
        "ax.set_xticks(ind)\n",
        "ax.set_xticklabels(('1', '2', '5', '10', '20'))\n",
        "ax.set_ylim([0.4,1.0])\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7ajiVRjd7sI"
      },
      "source": [
        "# from tensorflow.python.util import deprecation\n",
        "# deprecation._PRINT_DEPRECATION_WARNINGS = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpbsk8BT11ca"
      },
      "source": [
        "# tf.compat.v1.experimental.output_all_intermediates(True)\n",
        "# tf.compat.v1.enable_resource_variables()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Iek4T287EnNg",
        "outputId": "c4ae76c1-bbcc-4c49-bfa9-44ea50745e41"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvC1fvMLTuk2"
      },
      "source": [
        "# import os\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcLWXOIr-Aar"
      },
      "source": [
        "ALPHA = 2\n",
        "#number of activities\n",
        "NUM_CLASSES = 4\n",
        " \n",
        "# Hardcoded length of the sliding window mechanism employed to segment the data\n",
        "SLIDING_WINDOW_LENGTH = 60\n",
        " \n",
        "# Hardcoded step of the sliding window mechanism employed to segment the data\n",
        "# SLIDING_WINDOW_STEP = 160\n",
        " \n",
        "# Batch Size\n",
        "BATCH_SIZE = 100\n",
        " \n",
        "# Number filters convolutional layers\n",
        "NUM_FILTERS = 64\n",
        " \n",
        "# Size filters convolutional layers\n",
        "FILTER_SIZE = 5\n",
        " \n",
        "# Number of unit in the long short-term recurrent layers\n",
        "NUM_UNITS_LSTM = 128\n",
        " \n",
        "NUM_CHANNEL = 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfgQefxG-Qu2"
      },
      "source": [
        "#flatten data into matrix(28x28-->784),for sensor data no need to do this \n",
        "# =============================================================================\n",
        "# Load and preprocess training and testing data\n",
        "# =============================================================================\n",
        " \n",
        "# to load the windowed data\n",
        "def load_tensor(path, sensor):\n",
        "    # Read the array from disk\n",
        "    #new_data = np.loadtxt('./ActiveData/Sub'+str(name)+'_data.txt')\n",
        "    new_data = np.loadtxt(path)\n",
        "    \n",
        "    #changing NUM_CHANNEL according to sensor combination type\n",
        "    combination = ['WT', 'AW']\n",
        "    single = ['A', 'W', 'T']\n",
        "    if sensor in combination:\n",
        "        NUM_CHANNEL = 6\n",
        "    elif sensor in single:\n",
        "        NUM_CHANNEL = 3\n",
        "    else:\n",
        "        NUM_CHANNEL = 9\n",
        " \n",
        "    # Note that this returned a 2D array!\n",
        "    # print(new_data.shape)\n",
        "    \n",
        "    # However, going back to 3D is easy if we know the \n",
        "    # original shape of the array\n",
        "    if sensor == \"All\":\n",
        "        pass\n",
        "    elif sensor == \"WT\":\n",
        "        new_data = new_data[:,:6]\n",
        "    elif sensor == \"AW\":\n",
        "        new_data = new_data[:,3:]\n",
        "    elif sensor == 'A':\n",
        "        new_data = new_data[:,6:]\n",
        "    elif sensor == 'W':\n",
        "        new_data = new_data[:,3:6]\n",
        "    elif sensor == 'T':\n",
        "        new_data = new_data[:,:3]\n",
        " \n",
        "    new_data = new_data.reshape((-1, SLIDING_WINDOW_LENGTH, NUM_CHANNEL))\n",
        " \n",
        "    return new_data, NUM_CHANNEL\n",
        " \n",
        "def load_by_trial(trial_id, arg, sensor): \n",
        "    #arg can be either 'train' or 'test'\n",
        "    path = '/content/drive/MyDrive/MITACS_Nithin/juravinski/data/trial'+str(trial_id)+'/*_'+arg+'_data.txt'\n",
        "    x_list = glob.glob(path)\n",
        "    # path = '/content/drive/MyDrive/MITACS/juravinski/data/trial'+str(trial_id)+'/*_train_label.txt'\n",
        "    # y_list = glob.glob(path)\n",
        "    y_list = [i[0:-8]+'label.txt' for i in x_list]\n",
        "    X,Y = [],[]\n",
        "    for i in tqdm(range(len(x_list)-19)):\n",
        "        x, channels = load_tensor(x_list[i], sensor)\n",
        "        y = np.loadtxt(y_list[i])\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "    # x_ = convert_list(X)\n",
        "    # y_ = convert_y(Y)\n",
        "    # idx = np.where(y_==4)\n",
        "    # y_[idx] = 3 \n",
        "    return X, Y, channels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpreHDq5-h32"
      },
      "source": [
        "# =============================================================================\n",
        "# load data and train\n",
        "# in the order of ['thigh','wrist','ankle']\n",
        "# =============================================================================\n",
        "sensor = 'All'\n",
        "x1,y1,channels = load_by_trial(1, 'train', sensor)\n",
        "x2,y2,channels = load_by_trial(2, 'train', sensor)\n",
        "X = []\n",
        "Y = []\n",
        " \n",
        "for i in range(10):\n",
        "    x = np.concatenate((x1[i], x2[i]), axis=0)I hope you received the MILA link previously; if not, I may resend it.\n",
        "    y1_ = y1[i]\n",
        "    idx = np.where(y1_==4)\n",
        "    y1_[idx] = 3\n",
        "    y2_ = y2[i]\n",
        "    idx = np.where(y2_==4)\n",
        "    y2_[idx] = 3\n",
        "    y = np.concatenate((y1_, y2_), axis=0)\n",
        "    X.append(x)\n",
        "    Y.append(y)\n",
        " \n",
        "# print(X_train[0].shape)\n",
        "# print(y_train[0].shape)\n",
        "\n",
        "y_train,y_val, X_train, X_val = [],[],[],[]\n",
        "for i in range(10):\n",
        "    x_t, x_v, y_t, y_v = train_test_split(X[i],Y[i],stratify=Y[i],test_size=0.1,random_state=42)\n",
        "    X_train.append(x_t)\n",
        "    X_val.append(x_v)\n",
        "    y_train.append(y_t)\n",
        "    y_val.append(y_v) \n",
        "                 \n",
        "    \n",
        "import collections\n",
        " \n",
        "# X_train = np.vstack((x1,x2))\n",
        "# y_train = np.concatenate((y1,y2))\n",
        "# print(collections.Counter(y_train))\n",
        " \n",
        "# from imblearn.over_sampling import RandomOverSampler\n",
        "# oversample = RandomOverSampler()\n",
        "# X_train = X_train.reshape(-1,SLIDING_WINDOW_LENGTH*channels)\n",
        "# X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "# print(collections.Counter(y_train))\n",
        "# X_train = X_train.reshape(-1,1,SLIDING_WINDOW_LENGTH,channels)\n",
        " \n",
        " \n",
        "labels = np.array([0,1,2,3])\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit(y=labels)\n",
        " \n",
        "# y_onehot_train = lb.transform(y_train) \n",
        "NUM_CHANNEL = channels\n",
        " \n",
        "# print(len(X_train))\n",
        " \n",
        "#3. flatten the 60X12 part ---- why??\n",
        "x_train_flat = []\n",
        "x_val_flat = []\n",
        " \n",
        "for i in range(10):\n",
        "    x_train_flat.append(X_train[i].reshape(-1,540))\n",
        "    x_val_flat.append(X_val[i].reshape(-1,540))\n",
        "    #the fewest label is 16 and 161 respectively, so pick m=16 n=160\n",
        "    print(collections.Counter(y_train[i].ravel()))\n",
        "    print(collections.Counter(y_val[i].ravel()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L3zZvMY-2dU"
      },
      "source": [
        "# =============================================================================\n",
        "# Replicate triplet nn method\n",
        "# 1. preprocess data into triplets\n",
        "#   This data generator has to be updated as the memory can't bear all these samples\n",
        "# 2. construct triplet nn\n",
        "# =============================================================================\n",
        "def generate_triplet(x,y,ap_pairs,an_pairs):\n",
        "    \"\"\"\n",
        "    To generate triplet from original dataset\n",
        "    Arguments:\n",
        "    ap_pairs -- how many random anchor-positive samples generate for a given class\n",
        "    an_pairs -- how many random anchor-negative samples generate for a given class\n",
        "                Does not required to be the same as ap_pairs, but for banlancing, should set the same?\n",
        "    \n",
        "    Returns:\n",
        "    triplet_pairs -- 3d tensor; its shape[0]=NUM_CLASSES*ap_pairs*an_pairs\n",
        "    \"\"\"\n",
        "    data_xy = tuple([x,y])\n",
        " \n",
        "    triplet_pairs = []\n",
        "    labels = []\n",
        "   \n",
        "    for data_class in sorted(set(data_xy[1])):\n",
        "        same_class_idx = np.where((data_xy[1] == data_class))[0]\n",
        "        diff_class_idx = np.where(data_xy[1] != data_class)[0]\n",
        "        \n",
        "        if same_class_idx.shape[0] == 1:\n",
        "               same_ = [(same_class_idx[0],same_class_idx[0])]\n",
        "        else:\n",
        "            same_ = list(combinations(same_class_idx,2))\n",
        "        diff_ = list(diff_class_idx)\n",
        "        if len(same_) >= ap_pairs:\n",
        "            A_P_pairs = random.sample(same_,k=ap_pairs) #Generating Anchor-Positive pairs\n",
        "        else:\n",
        "            A_P_pairs = same_\n",
        "        if len(diff_) >= an_pairs:\n",
        "            Neg_idx = random.sample(diff_,k=an_pairs)\n",
        "        else:\n",
        "            Neg_idx = diff_\n",
        "        \n",
        "        #Put data into triplets according to the indices in (A_P_pairs and Neg_idx)\n",
        "        A_P_len = len(A_P_pairs)\n",
        "        #print(A_P_len)\n",
        "        for ap in A_P_pairs[:int(A_P_len)]:\n",
        "            Anchor = data_xy[0][ap[0]]\n",
        "            Positive = data_xy[0][ap[1]]\n",
        "            for n in Neg_idx:\n",
        "                Negative = data_xy[0][n]\n",
        "                triplet_pairs.append([Anchor,Positive,Negative])\n",
        "                labels.append(data_class)\n",
        "                \n",
        "    return np.array(triplet_pairs),np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMgzGkHn-5Go"
      },
      "source": [
        "# =============================================================================\n",
        "# Loss function\n",
        "# =============================================================================\n",
        "def triplet_loss(model, alpha = 0.4):\n",
        "    \"\"\"\n",
        "    Implementation of the triplet loss function\n",
        "    Arguments:\n",
        "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor data\n",
        "            positive -- the encodings for the positive data (similar to anchor)\n",
        "            negative -- the encodings for the negative data (different from anchor)\n",
        "    Returns:\n",
        "    loss -- real number, value of the loss\n",
        "    \"\"\"\n",
        "    myy_pred = model.get_layer(\"merged_layer\").output\n",
        "    #print('triplet NN.shape = ',myy_pred)\n",
        "    \n",
        "    total_lenght = myy_pred.shape.as_list()[-1]\n",
        "#     print('total_lenght=',  total_lenght)\n",
        "#     total_lenght =12\n",
        "    \n",
        "    anchor = myy_pred[:,0:int(total_lenght*1/3)]\n",
        "    positive = myy_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
        "    negative = myy_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
        " \n",
        "    # distance between the anchor and the positive\n",
        "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
        " \n",
        "    # distance between the anchor and the negative\n",
        "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
        " \n",
        "    # compute loss\n",
        "    basic_loss = pos_dist-neg_dist+alpha\n",
        "    loss = K.maximum(basic_loss,0.0)\n",
        " \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seuIMYOF-6Wz"
      },
      "source": [
        "def multi_task_loss(model, alpha = 1):\n",
        "    def _loss(y_true, y_pred):\n",
        "        myloss = K.mean(K.binary_crossentropy(y_true, y_pred))\n",
        "        miu = 0.8\n",
        "        S0 = model.layers[5].get_weights()[0]\n",
        "        S1 = model.layers[6].get_weights()[0]\n",
        "        S2 = model.layers[7].get_weights()[0]\n",
        "        S3 = model.layers[8].get_weights()[0]\n",
        "        \n",
        "        S4 = model.layers[9].get_weights()[0]\n",
        "        S5 = model.layers[10].get_weights()[0]\n",
        "        S6 = model.layers[11].get_weights()[0]\n",
        "        S7 = model.layers[12].get_weights()[0]\n",
        "        \n",
        "        S8 = model.layers[13].get_weights()[0]\n",
        "        S9 = model.layers[14].get_weights()[0]\n",
        "        \n",
        "        S = np.hstack((S0,S1,S2,S3,S4,S5,S6,S7,S8,S9))\n",
        "#        myloss+= miu*np.linalg.norm(S[0].reshape(-1,5),ord=1)\n",
        "        myloss+= miu*np.linalg.norm(S,ord=1)\n",
        "       \n",
        "        return myloss*alpha + triplet_loss(model)\n",
        "    return _loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZrY5d9ZdPuF"
      },
      "source": [
        "class BaseDenseAttention(keras.layers.Layer):\n",
        "  def __init__(self, causal=False, dropout=0.0,\n",
        "               **kwargs):\n",
        "    super(BaseDenseAttention, self).__init__(**kwargs)\n",
        "    self.causal = causal\n",
        "    self.dropout = dropout\n",
        "    self.supports_masking = True\n",
        "\n",
        "  def _calculate_scores(self, query, key):\n",
        "    return NotImplementedError\n",
        "\n",
        "  def _apply_scores(self, scores, value, scores_mask=None, training=None):\n",
        "    if scores_mask is not None:\n",
        "      padding_mask = math_ops.logical_not(scores_mask)\n",
        "      # Bias so padding positions do not contribute to attention distribution.\n",
        "      # Note 65504. is the max float16 value.\n",
        "      if scores.dtype is dtypes.float16:\n",
        "        scores -= 65504. * math_ops.cast(padding_mask, dtype=scores.dtype)\n",
        "      else:\n",
        "        scores -= 1.e9 * math_ops.cast(padding_mask, dtype=scores.dtype)\n",
        "    if training is None:\n",
        "      training = backend.learning_phase()\n",
        "    weights = nn.softmax(scores)\n",
        "\n",
        "    def dropped_weights():\n",
        "      return nn.dropout(weights, rate=self.dropout)\n",
        "\n",
        "    # weights = control_flow_util.smart_cond(training, dropped_weights,\n",
        "    #                                        lambda: array_ops.identity(weights))\n",
        "    return math_ops.matmul(weights, value), weights\n",
        "\n",
        "  # TODO(b/125916026): Consider exposing a __call__ method with named args.\n",
        "  def call(self,\n",
        "           inputs,\n",
        "           mask=None,\n",
        "           training=None,\n",
        "           return_attention_scores=False):\n",
        "    self._validate_call_args(inputs=inputs, mask=mask)\n",
        "    q = inputs[0]\n",
        "    v = inputs[1]\n",
        "    k = inputs[2] if len(inputs) > 2 else v\n",
        "    q_mask = mask[0] if mask else None\n",
        "    v_mask = mask[1] if mask else None\n",
        "    scores = self._calculate_scores(query=q, key=k)\n",
        "    if v_mask is not None:\n",
        "      # Mask of shape [batch_size, 1, Tv].\n",
        "      v_mask = array_ops.expand_dims(v_mask, axis=-2)\n",
        "    if self.causal:\n",
        "      # Creates a lower triangular mask, so position i cannot attend to\n",
        "      # positions j>i. This prevents the flow of information from the future\n",
        "      # into the past.\n",
        "      scores_shape = array_ops.shape(scores)\n",
        "      # causal_mask_shape = [1, Tq, Tv].\n",
        "      causal_mask_shape = array_ops.concat(\n",
        "          [array_ops.ones_like(scores_shape[:-2]), scores_shape[-2:]],\n",
        "          axis=0)\n",
        "      causal_mask = _lower_triangular_mask(causal_mask_shape)\n",
        "    else:\n",
        "      causal_mask = None\n",
        "    # scores_mask = _merge_masks(v_mask, causal_mask)\n",
        "    result, attention_scores = self._apply_scores(\n",
        "        scores=scores, value=v, training=training) #scores_mask=scores_mask\n",
        "    if q_mask is not None:\n",
        "      # Mask of shape [batch_size, Tq, 1].\n",
        "      q_mask = array_ops.expand_dims(q_mask, axis=-1)\n",
        "      result *= math_ops.cast(q_mask, dtype=result.dtype)\n",
        "    if return_attention_scores:\n",
        "      return result, attention_scores\n",
        "    return result\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    self._validate_call_args(inputs=inputs, mask=mask)\n",
        "    if mask:\n",
        "      q_mask = mask[0]\n",
        "      if q_mask is None:\n",
        "        return None\n",
        "      return ops.convert_to_tensor_v2_with_dispatch(q_mask)\n",
        "    return None\n",
        "\n",
        "  def _validate_call_args(self, inputs, mask):\n",
        "    \"\"\"Validates arguments of the call method.\"\"\"\n",
        "    class_name = self.__class__.__name__\n",
        "    if not isinstance(inputs, list):\n",
        "      raise ValueError(\n",
        "          '{} layer must be called on a list of inputs, namely [query, value] '\n",
        "          'or [query, value, key].'.format(class_name))\n",
        "    if len(inputs) < 2 or len(inputs) > 3:\n",
        "      raise ValueError(\n",
        "          '{} layer accepts inputs list of length 2 or 3, '\n",
        "          'namely [query, value] or [query, value, key]. '\n",
        "          'Given length: {}'.format(class_name, len(inputs)))\n",
        "    if mask:\n",
        "      if not isinstance(mask, list):\n",
        "        raise ValueError(\n",
        "            '{} layer mask must be a list, '\n",
        "            'namely [query_mask, value_mask].'.format(class_name))\n",
        "      if len(mask) < 2 or len(mask) > len(inputs):\n",
        "        raise ValueError(\n",
        "            '{} layer mask must be a list of length 2, namely [query_mask, '\n",
        "            'value_mask]. Given length: {}'.format(class_name, len(mask)))\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        'causal': self.causal,\n",
        "        'dropout': self.dropout,\n",
        "    }\n",
        "    base_config = super(BaseDenseAttention, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "# @keras_export('keras.layers.Attention')\n",
        "class Attention(BaseDenseAttention):\n",
        "  def __init__(self, use_scale=False, **kwargs):\n",
        "    super(Attention, self).__init__(**kwargs)\n",
        "    self.use_scale = use_scale\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    \"\"\"Creates scale variable if use_scale==True.\"\"\"\n",
        "    if self.use_scale:\n",
        "      self.scale = self.add_weight(\n",
        "          name='scale',\n",
        "          shape=(),\n",
        "          initializer=init_ops.ones_initializer(),\n",
        "          dtype=self.dtype,\n",
        "          trainable=True)\n",
        "    else:\n",
        "      self.scale = None\n",
        "    super(Attention, self).build(input_shape)\n",
        "\n",
        "  def _calculate_scores(self, query, key):\n",
        "    scores = math_ops.matmul(query, key, transpose_b=True)\n",
        "    if self.scale is not None:\n",
        "      scores *= self.scale\n",
        "    return scores\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {'use_scale': self.use_scale}\n",
        "    base_config = super(Attention, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXWABgJ2-_eh"
      },
      "source": [
        "# =============================================================================\n",
        "# Construct the neural network\n",
        "# =============================================================================\n",
        "#The 'Net' part, will be replaced by 4CNN+2LSTM\n",
        "def Conv_Att_LSTM(cpu=False, attention = \"Luong\", dropout = 0.2):  #specify type of attention as a param\n",
        "\n",
        "    multi_input = Input(shape=(1, SLIDING_WINDOW_LENGTH, NUM_CHANNEL), name='multi_input')\n",
        "    format = 'channels_first'\n",
        "\n",
        "    if attention == \"Luong\":\n",
        "        attention1 = Attention(dropout = dropout)\n",
        "        attention2 = Attention(dropout = dropout)\n",
        "    # elif attention == 'MultiHead':\n",
        "    #     attention1 = MultiHeadAttention(num_heads=4)\n",
        "    #     attention2 = MultiHeadAttention(num_heads=4)\n",
        "    \n",
        "    \n",
        "    y = Conv2D(64, (5, 1), activation='relu', data_format=format)(multi_input)\n",
        "\n",
        "    y = Conv2D(64, (5, 1), activation='relu', data_format=format)(y)\n",
        "\n",
        "    y = Conv2D(64, (5, 1), activation='relu', data_format=format)(y)\n",
        "\n",
        "    y = Conv2D(64, (5, 1), activation='relu', data_format=format)(y\n",
        "\n",
        "    y = Permute((2, 1, 3))(y)\n",
        "\n",
        "    y = Reshape((int(y.shape[1]), int(y.shape[2]) * int(y.shape[3])))(y) #(44,576)\n",
        "\n",
        "    #adding attention layer, type of attention specified above\n",
        "\n",
        "    y = attention1([y,y]) #attention layer - more like self attention but used along with conv and lstm\n",
        "    \n",
        "    y = LSTM(128,dropout=0.25,return_sequences=True)(y) #(44,128)\n",
        "\n",
        "    y = attention2([y,y])\n",
        "\n",
        "    y = LSTM(128)(y)\n",
        "\n",
        "    # y = attention([y,y])\n",
        "\n",
        "    return Model(inputs=multi_input, outputs=y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG0jEu2US1xY"
      },
      "source": [
        "# =============================================================================\n",
        "# Construct the neural network\n",
        "# =============================================================================\n",
        "#The 'Net' part, will be replaced by 4CNN+2LSTM\n",
        "def Conv_Att_LSTM(cpu=False, attention = \"Luong\", dropout = 0.2):  #specify type of attention as a param\n",
        "\n",
        "    multi_input = Input(shape=(1, SLIDING_WINDOW_LENGTH, NUM_CHANNEL), name='multi_input')\n",
        "    format = 'channels_first'\n",
        "\n",
        "    if attention == \"Luong\":\n",
        "        attention1 = Attention(dropout = dropout)\n",
        "        attention2 = Attention(dropout = dropout)\n",
        "    # elif attention == 'MultiHead':\n",
        "    #     attention1 = MultiHeadAttention(num_heads=4)\n",
        "    #     attention2 = MultiHeadAttention(num_heads=4)\n",
        "\n",
        "    \n",
        "    y = Conv2D(64, (5, 1), activation='relu', data_format=format)(multi_input)\n",
        "    \n",
        "    y = Conv2D(64, (5, 1), activation='relu', data_format=format)(y)  \n",
        "\n",
        "    y = Conv2D(64, (5, 1), activation='relu', data_format=format)(y)\n",
        "\n",
        "    y = Conv2D(64, (5, 1), activation='relu', data_format=format)(y)\n",
        "\n",
        "    y = Permute((2, 1, 3))(y)\n",
        "  \n",
        "    y = Reshape((int(y.shape[1]), int(y.shape[2]) * int(y.shape[3])))(y)\n",
        "   \n",
        "    #adding attention layer, type of attention specified above\n",
        "\n",
        "    query_encoding1 = Dense(300, activation='relu')(y)\n",
        "\n",
        "    value_encoding1 = Dense(300, activation='relu')(y)\n",
        "\n",
        "    y = attention1([query_encoding1,value_encoding1]) #attention layer - more like self attention but used along with conv and lstm\n",
        "    \n",
        "    y = LSTM(128,dropout=0.25,return_sequences=True)(y)\n",
        "\n",
        "    query_encoding2 = Dense(int(y.shape[2]), activation='relu')(y)\n",
        "\n",
        "    value_encoding2 = Dense(int(y.shape[2]), activation='relu')(y)\n",
        "\n",
        "    y = attention2([query_encoding2,value_encoding2])\n",
        "\n",
        "    y = LSTM(128)(y)\n",
        "\n",
        "    # y = attention([y,y])\n",
        "\n",
        "    return Model(inputs=multi_input, outputs=y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnXK1Ln4zj08"
      },
      "source": [
        "# from tensorflow.python.framework.ops import disable_eager_execution\n",
        "# disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9s4DkV4_e9o"
      },
      "source": [
        "# =============================================================================\n",
        "# Construct the training process\n",
        "# The Si layers are from 5 to 21\n",
        "# =============================================================================\n",
        "# from keras.models import model_from_json\n",
        "# json_file = open('/content/drive/MyDrive/MITACS_Nithin/juravinski/T-MTL_Models/trimtl_model_usall.json', 'r')\n",
        "# loaded_model_json = json_file.read()\n",
        "# json_file.close()\n",
        "# model = model_from_json(loaded_model_json)\n",
        "# # load weights into new model\n",
        "# model.load_weights(\"/content/drive/MyDrive/MITACS_Nithin/juravinski/T-MTL_Models/trimtl_model_usall.h5\")\n",
        "# print(\"Loaded model from disk\")\n",
        "# print(model.summary())\n",
        "# adam_optim = Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
        "# model.compile(loss=multi_task_loss(model,ALPHA), optimizer=adam_optim)\n",
        "\n",
        "count = 0\n",
        "epochs = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOicIvNCFGZM"
      },
      "source": [
        "##Alternate TF Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPBNO7xA_iNN"
      },
      "source": [
        "#get the triplets for training process\n",
        "def get_triplets(xtrain):\n",
        "    Anchor = xtrain[:,0,:].reshape(-1,1,SLIDING_WINDOW_LENGTH,NUM_CHANNEL)\n",
        "    Positive = xtrain[:,1,:].reshape(-1,1,SLIDING_WINDOW_LENGTH,NUM_CHANNEL)\n",
        "    Negative = xtrain[:,2,:].reshape(-1,1,SLIDING_WINDOW_LENGTH,NUM_CHANNEL)\n",
        "    return Anchor,Positive,Negative\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l-jlb___k6N"
      },
      "source": [
        "# generate triplets and store them in lists: X_train_,y_train_; X_val and y_val just from one subject, and they're arrays\n",
        "# divide into anchor,positive,and negative as input\n",
        "def get_train_val(x_train_flat,y_train):\n",
        "    print('start generating triplets')\n",
        "    m = 50\n",
        "    n = 20\n",
        "    X_train_ = []\n",
        "    y_train_ = []\n",
        "    X_val_=[]\n",
        "    y_val_=[]\n",
        "    anchor_,positive_,negative_, anchor_test, positive_test, negative_test = [],[],[],[],[],[]\n",
        "    for i in range(10):\n",
        "        tempx,tempy = generate_triplet(x_train_flat[i],y_train[i].ravel(),ap_pairs=m,an_pairs=m)\n",
        "        X_train_.append(tempx)\n",
        "        y_train_.append(tempy)\n",
        "        tempa,tempp,tempn = get_triplets(tempx)\n",
        "        anchor_.append(tempa)\n",
        "        positive_.append(tempp)\n",
        "        negative_.append(tempn)\n",
        "        \n",
        "        tempx,tempy = generate_triplet(x_val_flat[i],y_val[i].ravel(),ap_pairs=n,an_pairs=n)\n",
        "        X_val_.append(tempx)\n",
        "        y_val_.append(tempy)\n",
        "        tempa,tempp,tempn = get_triplets(tempx)\n",
        "        anchor_test.append(tempa)\n",
        "        positive_test.append(tempp)\n",
        "        negative_test.append(tempn)\n",
        "        \n",
        "    return anchor_,positive_,negative_,anchor_test, positive_test,negative_test, y_train_, y_val_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFSgSwAccS4A"
      },
      "source": [
        "def make_ytrain(y):\n",
        "    y_onehot = lb.transform(y)\n",
        "    y_onehot = np.float32(y_onehot)\n",
        "    res = []\n",
        "    for i in range(10):\n",
        "        res.append(y_onehot)   \n",
        "    return res\n",
        "\n",
        "def convert_list(my_list):\n",
        "    length = len(my_list)\n",
        "    if length==0:\n",
        "        return\n",
        "    res = my_list[0]\n",
        "    for i in range(1,length):\n",
        "        res = np.vstack((res,my_list[i]))\n",
        "    return res\n",
        "\n",
        "def convert_y(my_list):\n",
        "    length = len(my_list)\n",
        "    if length==0:\n",
        "        return\n",
        "    res = my_list[0]\n",
        "    for i in range(1,length):\n",
        "        res = np.concatenate((res,my_list[i]))\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6N_1fSZqZUi",
        "outputId": "9d015ad0-71aa-4f0a-b228-154f502a74b0"
      },
      "source": [
        "anchor_input = Input((1,SLIDING_WINDOW_LENGTH,NUM_CHANNEL), name='anchor_input')\n",
        "positive_input = Input((1,SLIDING_WINDOW_LENGTH,NUM_CHANNEL), name='positive_input')\n",
        "negative_input = Input((1,SLIDING_WINDOW_LENGTH,NUM_CHANNEL), name='negative_input')\n",
        "\n",
        "# Shared embedding layer for positive and negative items\n",
        "Shared_DNN = Conv_Att_LSTM(attention='Luong')\n",
        "\n",
        "encoded_anchor = Shared_DNN(anchor_input)\n",
        "encoded_positive = Shared_DNN(positive_input)\n",
        "encoded_negative = Shared_DNN(negative_input)\n",
        "\n",
        "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
        "\n",
        "finalAct = 'softmax'\n",
        "sub1 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)\n",
        "sub2 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)\n",
        "sub3 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)\n",
        "sub4 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector) \n",
        "\n",
        "sub5 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)\n",
        "sub6 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)\n",
        "sub7 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)\n",
        "sub8 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector) \n",
        "\n",
        "sub9 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)\n",
        "sub10 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)\n",
        "# sub11 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)\n",
        "# sub12 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector) \n",
        "\n",
        "# sub13 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)  \n",
        "# sub14 = Dense(NUM_CLASSES,use_bias=True,activation=finalAct)(merged_vector)  \n",
        "\n",
        "model = Model(inputs=[anchor_input,positive_input, negative_input], \n",
        "            outputs=[sub1,sub2,sub3,sub4,sub5,sub6,sub7,sub8,sub9,sub10])\n",
        "model.load_weights(\"/content/drive/MyDrive/MITACS_Nithin/juravinski/T-MTL_Models/trimtl_model_usall_new_rest.h5\")\n",
        "# print(\"Loaded model from disk\")\n",
        "# print(model.summary())\n",
        "adam_optim = Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999)\n",
        "model.compile(loss=multi_task_loss(model,ALPHA), optimizer=adam_optim)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "anchor_input (InputLayer)       (None, 1, 60, 9)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positive_input (InputLayer)     (None, 1, 60, 9)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "negative_input (InputLayer)     (None, 1, 60, 9)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 128)          554560      anchor_input[0][0]               \n",
            "                                                                 positive_input[0][0]             \n",
            "                                                                 negative_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "merged_layer (Concatenate)      (None, 384)          0           model_1[1][0]                    \n",
            "                                                                 model_1[2][0]                    \n",
            "                                                                 model_1[3][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            1540        merged_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4)            1540        merged_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 4)            1540        merged_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            1540        merged_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 4)            1540        merged_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 4)            1540        merged_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 4)            1540        merged_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 4)            1540        merged_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 4)            1540        merged_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 4)            1540        merged_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 569,960\n",
            "Trainable params: 569,960\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFGl2UXkuOBy"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMniN59i8KJK",
        "outputId": "83999761-d480-4503-a66d-e384df2a9e42"
      },
      "source": [
        "\n",
        "for count in tqdm(range(epochs)):\n",
        "\n",
        "#Get the training and validation data for current epoch\n",
        "    anchor_,positive_,negative_,anchor_test,positive_test,negative_test,y_train_,y_val_ = get_train_val(x_train_flat,y_train)\n",
        "\n",
        "    #freeze all Si layers(from 5 to 20)\n",
        "    for i in range(5,15):\n",
        "        model.layers[i].trainable = False\n",
        "        \n",
        "    #fix all Si and update L first\n",
        "    #if count>0:\n",
        "    trainset_anchor = convert_list(anchor_)\n",
        "    trainset_Positive = convert_list(positive_)\n",
        "    trainset_Negative = convert_list(negative_)\n",
        "    validation_anchor = convert_list(anchor_test)\n",
        "    validation_positive = convert_list(positive_test)\n",
        "    validation_negative = convert_list(negative_test)\n",
        "    traintarget = convert_y(y_train_)\n",
        "    target_onehot = make_ytrain(traintarget)\n",
        "    testtarget = convert_y(y_val_)\n",
        "    test_onehot = make_ytrain(testtarget)\n",
        "    print(trainset_anchor.shape,traintarget.shape)\n",
        "    #make L layers trainable   \n",
        "    for i in range(11):\n",
        "        model.layers[3].layers[i].trainable = True\n",
        "    #model.compile(loss=custom_loss(model),\n",
        "\n",
        "    model.compile(loss=multi_task_loss(model,ALPHA),optimizer = adam_optim)\n",
        "        \n",
        "    model.fit([trainset_anchor,trainset_Positive,trainset_Negative],\n",
        "    y=target_onehot,validation_data=([validation_anchor,validation_positive,validation_negative],test_onehot), batch_size=512, epochs=1)\n",
        "\n",
        "#Before training Si, freeze L\n",
        "    for i in range(11):\n",
        "        model.layers[3].layers[i].trainable = False\n",
        "\n",
        "    #train Si(i=5 to 20) branch, freeze all the other S branches\n",
        "    for j in range(5,15):\n",
        "        #freeze all Si\n",
        "        for i in range(5,15):\n",
        "            model.layers[i].trainable = False\n",
        "        #make current Si trainable\n",
        "        model.layers[j].trainable = True\n",
        "        trainset_anchor = anchor_[j-5]\n",
        "        trainset_Positive = positive_[j-5]\n",
        "        trainset_Negative = negative_[j-5]\n",
        "        y=make_ytrain(y_train_[j-5])\n",
        "        \n",
        "        validation_anchor = anchor_test[j-5]\n",
        "        validation_Positive = positive_test[j-5]\n",
        "        validation_Negative = negative_test[j-5]\n",
        "        test_ = make_ytrain(y_val_[j-5])\n",
        "    \n",
        "        model.compile(loss=multi_task_loss(model,ALPHA),metrics = ['accuracy'], optimizer=adam_optim)\n",
        "            # is that necessary to do cross validation for each branch?\n",
        "        \n",
        "        model.fit([trainset_anchor,trainset_Positive,trainset_Negative],y,\n",
        "            validation_data=([validation_anchor,validation_Positive,validation_Negative],test_),\n",
        "            batch_size=512, \n",
        "            epochs=1)\n",
        "            \n",
        "        #save model to file every epochs\n",
        "#       trained_model = Model(inputs=anchor_input, outputs=[sub1,sub2,sub3,sub4,sub5,sub6,sub7,sub8,sub9,\n",
        "#                                sub10,sub11,sub12,sub13,sub14,sub15,sub16])\n",
        "    # model.save('/content/drive/MyDrive/MITACS_Nithin/juravinski/T-MTL_Models/trimtl_model_usall_tf',save_format='tf')\n",
        "\n",
        "\n",
        "    model_json = model.to_json()\n",
        "    with open(\"/content/drive/MyDrive/MITACS_Nithin/juravinski/T-MTL_Models/trimtl_model_usall_new_rest.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(\"/content/drive/MyDrive/MITACS_Nithin/juravinski/T-MTL_Models/trimtl_model_usall_new_rest.h5\") \n",
        "\n",
        "    gc.collect() \n",
        "\n",
        "    del anchor_\n",
        "    del positive_\n",
        "    del negative_\n",
        "    del anchor_test\n",
        "    del positive_test\n",
        "    del negative_test\n",
        "    del y_train_\n",
        "    del y_val_\n",
        "\n",
        "    anchor_,positive_,negative_,anchor_test,positive_test,negative_test,y_train_,y_val_ =[],[],[],[],[],[],[],[]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "start generating triplets\n",
            "(100000, 1, 60, 9) (100000,)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 100000 samples, validate on 16000 samples\n",
            "Epoch 1/1\n",
            "100000/100000 [==============================] - 64s 645us/step - loss: 3221.2813 - dense_1_loss: 322.1283 - dense_2_loss: 322.1278 - dense_3_loss: 322.1280 - dense_4_loss: 322.1279 - dense_5_loss: 322.1279 - dense_6_loss: 322.1278 - dense_7_loss: 322.1280 - dense_8_loss: 322.1281 - dense_9_loss: 322.1280 - dense_10_loss: 322.1288 - val_loss: 3221.4038 - val_dense_1_loss: 322.1382 - val_dense_2_loss: 322.1402 - val_dense_3_loss: 322.1389 - val_dense_4_loss: 322.1400 - val_dense_5_loss: 322.1396 - val_dense_6_loss: 322.1393 - val_dense_7_loss: 322.1418 - val_dense_8_loss: 322.1405 - val_dense_9_loss: 322.1398 - val_dense_10_loss: 322.1388\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 3221.1781 - dense_1_loss: 322.1177 - dense_2_loss: 322.1177 - dense_3_loss: 322.1178 - dense_4_loss: 322.1177 - dense_5_loss: 322.1178 - dense_6_loss: 322.1177 - dense_7_loss: 322.1176 - dense_8_loss: 322.1177 - dense_9_loss: 322.1176 - dense_10_loss: 322.1181 - dense_1_accuracy: 1.0000 - dense_2_accuracy: 1.0000 - dense_3_accuracy: 1.0000 - dense_4_accuracy: 1.0000 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 1.0000 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 1.0000 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 0.9999 - val_loss: 3221.2649 - val_dense_1_loss: 322.1234 - val_dense_2_loss: 322.1232 - val_dense_3_loss: 322.1234 - val_dense_4_loss: 322.1232 - val_dense_5_loss: 322.1233 - val_dense_6_loss: 322.1233 - val_dense_7_loss: 322.1232 - val_dense_8_loss: 322.1232 - val_dense_9_loss: 322.1233 - val_dense_10_loss: 322.1233 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 3221.1768 - dense_1_loss: 322.1182 - dense_2_loss: 322.1171 - dense_3_loss: 322.1176 - dense_4_loss: 322.1183 - dense_5_loss: 322.1174 - dense_6_loss: 322.1172 - dense_7_loss: 322.1177 - dense_8_loss: 322.1177 - dense_9_loss: 322.1176 - dense_10_loss: 322.1174 - dense_1_accuracy: 0.9989 - dense_2_accuracy: 0.9996 - dense_3_accuracy: 0.9995 - dense_4_accuracy: 0.9990 - dense_5_accuracy: 0.9994 - dense_6_accuracy: 0.9995 - dense_7_accuracy: 0.9993 - dense_8_accuracy: 0.9993 - dense_9_accuracy: 0.9994 - dense_10_accuracy: 0.9995 - val_loss: 3221.1692 - val_dense_1_loss: 322.1168 - val_dense_2_loss: 322.1163 - val_dense_3_loss: 322.1171 - val_dense_4_loss: 322.1206 - val_dense_5_loss: 322.1177 - val_dense_6_loss: 322.1170 - val_dense_7_loss: 322.1184 - val_dense_8_loss: 322.1168 - val_dense_9_loss: 322.1184 - val_dense_10_loss: 322.1196 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 459us/step - loss: 3221.3587 - dense_1_loss: 322.1347 - dense_2_loss: 322.1349 - dense_3_loss: 322.1353 - dense_4_loss: 322.1359 - dense_5_loss: 322.1352 - dense_6_loss: 322.1349 - dense_7_loss: 322.1371 - dense_8_loss: 322.1359 - dense_9_loss: 322.1362 - dense_10_loss: 322.1358 - dense_1_accuracy: 0.9962 - dense_2_accuracy: 0.9961 - dense_3_accuracy: 0.9961 - dense_4_accuracy: 0.9958 - dense_5_accuracy: 0.9960 - dense_6_accuracy: 0.9958 - dense_7_accuracy: 0.9954 - dense_8_accuracy: 0.9959 - dense_9_accuracy: 0.9956 - dense_10_accuracy: 0.9954 - val_loss: 3221.7736 - val_dense_1_loss: 322.1637 - val_dense_2_loss: 322.1623 - val_dense_3_loss: 322.1628 - val_dense_4_loss: 322.1660 - val_dense_5_loss: 322.1615 - val_dense_6_loss: 322.1606 - val_dense_7_loss: 322.1657 - val_dense_8_loss: 322.1637 - val_dense_9_loss: 322.1634 - val_dense_10_loss: 322.1605 - val_dense_1_accuracy: 0.9806 - val_dense_2_accuracy: 0.9869 - val_dense_3_accuracy: 0.9825 - val_dense_4_accuracy: 0.9869 - val_dense_5_accuracy: 0.9837 - val_dense_6_accuracy: 0.9862 - val_dense_7_accuracy: 0.9875 - val_dense_8_accuracy: 0.9869 - val_dense_9_accuracy: 0.9869 - val_dense_10_accuracy: 0.9844\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 3221.3668 - dense_1_loss: 322.1372 - dense_2_loss: 322.1367 - dense_3_loss: 322.1369 - dense_4_loss: 322.1366 - dense_5_loss: 322.1369 - dense_6_loss: 322.1368 - dense_7_loss: 322.1366 - dense_8_loss: 322.1365 - dense_9_loss: 322.1368 - dense_10_loss: 322.1374 - dense_1_accuracy: 0.9997 - dense_2_accuracy: 1.0000 - dense_3_accuracy: 0.9998 - dense_4_accuracy: 1.0000 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 1.0000 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 0.9999 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 0.9998 - val_loss: 3222.4806 - val_dense_1_loss: 322.2086 - val_dense_2_loss: 322.2199 - val_dense_3_loss: 322.2135 - val_dense_4_loss: 322.2172 - val_dense_5_loss: 322.2202 - val_dense_6_loss: 322.2189 - val_dense_7_loss: 322.2286 - val_dense_8_loss: 322.2200 - val_dense_9_loss: 322.2201 - val_dense_10_loss: 322.2159 - val_dense_1_accuracy: 0.9875 - val_dense_2_accuracy: 0.9837 - val_dense_3_accuracy: 0.9875 - val_dense_4_accuracy: 0.9856 - val_dense_5_accuracy: 0.9850 - val_dense_6_accuracy: 0.9844 - val_dense_7_accuracy: 0.9844 - val_dense_8_accuracy: 0.9875 - val_dense_9_accuracy: 0.9869 - val_dense_10_accuracy: 0.9875\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 474us/step - loss: 3224.4512 - dense_1_loss: 322.4450 - dense_2_loss: 322.4448 - dense_3_loss: 322.4452 - dense_4_loss: 322.4456 - dense_5_loss: 322.4449 - dense_6_loss: 322.4449 - dense_7_loss: 322.4449 - dense_8_loss: 322.4449 - dense_9_loss: 322.4450 - dense_10_loss: 322.4457 - dense_1_accuracy: 0.9999 - dense_2_accuracy: 0.9999 - dense_3_accuracy: 0.9999 - dense_4_accuracy: 0.9996 - dense_5_accuracy: 0.9999 - dense_6_accuracy: 0.9999 - dense_7_accuracy: 0.9999 - dense_8_accuracy: 0.9999 - dense_9_accuracy: 0.9999 - dense_10_accuracy: 0.9996 - val_loss: 3224.4089 - val_dense_1_loss: 322.4403 - val_dense_2_loss: 322.4404 - val_dense_3_loss: 322.4402 - val_dense_4_loss: 322.4402 - val_dense_5_loss: 322.4403 - val_dense_6_loss: 322.4402 - val_dense_7_loss: 322.4402 - val_dense_8_loss: 322.4402 - val_dense_9_loss: 322.4402 - val_dense_10_loss: 322.4402 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 485us/step - loss: 3224.5149 - dense_1_loss: 322.4523 - dense_2_loss: 322.4514 - dense_3_loss: 322.4515 - dense_4_loss: 322.4519 - dense_5_loss: 322.4512 - dense_6_loss: 322.4514 - dense_7_loss: 322.4516 - dense_8_loss: 322.4517 - dense_9_loss: 322.4518 - dense_10_loss: 322.4526 - dense_1_accuracy: 0.9991 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9997 - dense_4_accuracy: 0.9997 - dense_5_accuracy: 0.9998 - dense_6_accuracy: 0.9998 - dense_7_accuracy: 0.9997 - dense_8_accuracy: 0.9995 - dense_9_accuracy: 0.9996 - dense_10_accuracy: 0.9990 - val_loss: 3224.4311 - val_dense_1_loss: 322.4421 - val_dense_2_loss: 322.4421 - val_dense_3_loss: 322.4421 - val_dense_4_loss: 322.4420 - val_dense_5_loss: 322.4420 - val_dense_6_loss: 322.4420 - val_dense_7_loss: 322.4420 - val_dense_8_loss: 322.4419 - val_dense_9_loss: 322.4419 - val_dense_10_loss: 322.4420 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 484us/step - loss: 3224.4381 - dense_1_loss: 322.4440 - dense_2_loss: 322.4438 - dense_3_loss: 322.4438 - dense_4_loss: 322.4439 - dense_5_loss: 322.4438 - dense_6_loss: 322.4436 - dense_7_loss: 322.4437 - dense_8_loss: 322.4438 - dense_9_loss: 322.4437 - dense_10_loss: 322.4440 - dense_1_accuracy: 0.9999 - dense_2_accuracy: 1.0000 - dense_3_accuracy: 1.0000 - dense_4_accuracy: 1.0000 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 1.0000 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 1.0000 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 0.9998 - val_loss: 3224.5700 - val_dense_1_loss: 322.4501 - val_dense_2_loss: 322.4533 - val_dense_3_loss: 322.4507 - val_dense_4_loss: 322.4547 - val_dense_5_loss: 322.4511 - val_dense_6_loss: 322.4524 - val_dense_7_loss: 322.4556 - val_dense_8_loss: 322.4578 - val_dense_9_loss: 322.4515 - val_dense_10_loss: 322.4510 - val_dense_1_accuracy: 0.9994 - val_dense_2_accuracy: 0.9919 - val_dense_3_accuracy: 0.9975 - val_dense_4_accuracy: 0.9919 - val_dense_5_accuracy: 0.9969 - val_dense_6_accuracy: 0.9919 - val_dense_7_accuracy: 0.9912 - val_dense_8_accuracy: 0.9912 - val_dense_9_accuracy: 0.9950 - val_dense_10_accuracy: 0.9956\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 500us/step - loss: 3224.5411 - dense_1_loss: 322.4542 - dense_2_loss: 322.4539 - dense_3_loss: 322.4539 - dense_4_loss: 322.4542 - dense_5_loss: 322.4539 - dense_6_loss: 322.4536 - dense_7_loss: 322.4536 - dense_8_loss: 322.4538 - dense_9_loss: 322.4538 - dense_10_loss: 322.4559 - dense_1_accuracy: 0.9998 - dense_2_accuracy: 1.0000 - dense_3_accuracy: 1.0000 - dense_4_accuracy: 1.0000 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 1.0000 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 1.0000 - dense_9_accuracy: 0.9999 - dense_10_accuracy: 0.9988 - val_loss: 3224.5480 - val_dense_1_loss: 322.4508 - val_dense_2_loss: 322.4523 - val_dense_3_loss: 322.4507 - val_dense_4_loss: 322.4514 - val_dense_5_loss: 322.4512 - val_dense_6_loss: 322.4507 - val_dense_7_loss: 322.4512 - val_dense_8_loss: 322.4510 - val_dense_9_loss: 322.4509 - val_dense_10_loss: 322.4509 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 516us/step - loss: 3224.4046 - dense_1_loss: 322.4409 - dense_2_loss: 322.4409 - dense_3_loss: 322.4407 - dense_4_loss: 322.4406 - dense_5_loss: 322.4405 - dense_6_loss: 322.4405 - dense_7_loss: 322.4405 - dense_8_loss: 322.4404 - dense_9_loss: 322.4405 - dense_10_loss: 322.4406 - dense_1_accuracy: 0.9997 - dense_2_accuracy: 0.9999 - dense_3_accuracy: 0.9998 - dense_4_accuracy: 1.0000 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 0.9999 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 1.0000 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 0.9999 - val_loss: 3224.5338 - val_dense_1_loss: 322.4505 - val_dense_2_loss: 322.4503 - val_dense_3_loss: 322.4501 - val_dense_4_loss: 322.4498 - val_dense_5_loss: 322.4502 - val_dense_6_loss: 322.4498 - val_dense_7_loss: 322.4499 - val_dense_8_loss: 322.4497 - val_dense_9_loss: 322.4499 - val_dense_10_loss: 322.4499 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 511us/step - loss: 3224.4801 - dense_1_loss: 322.4477 - dense_2_loss: 322.4478 - dense_3_loss: 322.4476 - dense_4_loss: 322.4481 - dense_5_loss: 322.4479 - dense_6_loss: 322.4477 - dense_7_loss: 322.4478 - dense_8_loss: 322.4479 - dense_9_loss: 322.4480 - dense_10_loss: 322.4476 - dense_1_accuracy: 1.0000 - dense_2_accuracy: 1.0000 - dense_3_accuracy: 1.0000 - dense_4_accuracy: 0.9999 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 1.0000 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 1.0000 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 1.0000 - val_loss: 3224.4193 - val_dense_1_loss: 322.4410 - val_dense_2_loss: 322.4410 - val_dense_3_loss: 322.4410 - val_dense_4_loss: 322.4410 - val_dense_5_loss: 322.4412 - val_dense_6_loss: 322.4411 - val_dense_7_loss: 322.4410 - val_dense_8_loss: 322.4410 - val_dense_9_loss: 322.4412 - val_dense_10_loss: 322.4410 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1/2 [05:44<05:44, 344.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "start generating triplets\n",
            "(100000, 1, 60, 9) (100000,)\n",
            "Train on 100000 samples, validate on 16000 samples\n",
            "Epoch 1/1\n",
            "100000/100000 [==============================] - 65s 650us/step - loss: 3224.5075 - dense_1_loss: 322.4509 - dense_2_loss: 322.4507 - dense_3_loss: 322.4507 - dense_4_loss: 322.4506 - dense_5_loss: 322.4508 - dense_6_loss: 322.4504 - dense_7_loss: 322.4503 - dense_8_loss: 322.4507 - dense_9_loss: 322.4505 - dense_10_loss: 322.4510 - val_loss: 3224.6952 - val_dense_1_loss: 322.4684 - val_dense_2_loss: 322.4691 - val_dense_3_loss: 322.4683 - val_dense_4_loss: 322.4680 - val_dense_5_loss: 322.4696 - val_dense_6_loss: 322.4692 - val_dense_7_loss: 322.4685 - val_dense_8_loss: 322.4686 - val_dense_9_loss: 322.4687 - val_dense_10_loss: 322.4692\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 543us/step - loss: 3224.4127 - dense_1_loss: 322.4411 - dense_2_loss: 322.4411 - dense_3_loss: 322.4413 - dense_4_loss: 322.4414 - dense_5_loss: 322.4414 - dense_6_loss: 322.4412 - dense_7_loss: 322.4412 - dense_8_loss: 322.4413 - dense_9_loss: 322.4413 - dense_10_loss: 322.4411 - dense_1_accuracy: 1.0000 - dense_2_accuracy: 1.0000 - dense_3_accuracy: 1.0000 - dense_4_accuracy: 1.0000 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 1.0000 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 1.0000 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 1.0000 - val_loss: 3224.5690 - val_dense_1_loss: 322.4557 - val_dense_2_loss: 322.4554 - val_dense_3_loss: 322.4572 - val_dense_4_loss: 322.4468 - val_dense_5_loss: 322.4506 - val_dense_6_loss: 322.4530 - val_dense_7_loss: 322.4530 - val_dense_8_loss: 322.4492 - val_dense_9_loss: 322.4509 - val_dense_10_loss: 322.4556 - val_dense_1_accuracy: 0.9900 - val_dense_2_accuracy: 0.9900 - val_dense_3_accuracy: 0.9900 - val_dense_4_accuracy: 0.9994 - val_dense_5_accuracy: 0.9937 - val_dense_6_accuracy: 0.9900 - val_dense_7_accuracy: 0.9900 - val_dense_8_accuracy: 0.9987 - val_dense_9_accuracy: 0.9931 - val_dense_10_accuracy: 0.9900\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 548us/step - loss: 3224.4045 - dense_1_loss: 322.4404 - dense_2_loss: 322.4403 - dense_3_loss: 322.4404 - dense_4_loss: 322.4406 - dense_5_loss: 322.4405 - dense_6_loss: 322.4403 - dense_7_loss: 322.4403 - dense_8_loss: 322.4404 - dense_9_loss: 322.4404 - dense_10_loss: 322.4405 - dense_1_accuracy: 1.0000 - dense_2_accuracy: 1.0000 - dense_3_accuracy: 1.0000 - dense_4_accuracy: 1.0000 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 1.0000 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 1.0000 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 0.9999 - val_loss: 3224.4504 - val_dense_1_loss: 322.4438 - val_dense_2_loss: 322.4434 - val_dense_3_loss: 322.4438 - val_dense_4_loss: 322.4437 - val_dense_5_loss: 322.4437 - val_dense_6_loss: 322.4433 - val_dense_7_loss: 322.4435 - val_dense_8_loss: 322.4435 - val_dense_9_loss: 322.4435 - val_dense_10_loss: 322.4438 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 552us/step - loss: 3224.6096 - dense_1_loss: 322.4619 - dense_2_loss: 322.4610 - dense_3_loss: 322.4608 - dense_4_loss: 322.4607 - dense_5_loss: 322.4613 - dense_6_loss: 322.4610 - dense_7_loss: 322.4605 - dense_8_loss: 322.4605 - dense_9_loss: 322.4609 - dense_10_loss: 322.4612 - dense_1_accuracy: 0.9999 - dense_2_accuracy: 0.9999 - dense_3_accuracy: 1.0000 - dense_4_accuracy: 1.0000 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 1.0000 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 1.0000 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 1.0000 - val_loss: 3224.7913 - val_dense_1_loss: 322.4686 - val_dense_2_loss: 322.4705 - val_dense_3_loss: 322.4680 - val_dense_4_loss: 322.4785 - val_dense_5_loss: 322.4702 - val_dense_6_loss: 322.4683 - val_dense_7_loss: 322.4687 - val_dense_8_loss: 322.4717 - val_dense_9_loss: 322.4701 - val_dense_10_loss: 322.4667 - val_dense_1_accuracy: 0.9975 - val_dense_2_accuracy: 0.9975 - val_dense_3_accuracy: 0.9981 - val_dense_4_accuracy: 0.9887 - val_dense_5_accuracy: 0.9962 - val_dense_6_accuracy: 0.9975 - val_dense_7_accuracy: 0.9981 - val_dense_8_accuracy: 0.9962 - val_dense_9_accuracy: 0.9975 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 564us/step - loss: 3224.5344 - dense_1_loss: 322.4538 - dense_2_loss: 322.4534 - dense_3_loss: 322.4533 - dense_4_loss: 322.4536 - dense_5_loss: 322.4537 - dense_6_loss: 322.4532 - dense_7_loss: 322.4532 - dense_8_loss: 322.4532 - dense_9_loss: 322.4535 - dense_10_loss: 322.4533 - dense_1_accuracy: 1.0000 - dense_2_accuracy: 1.0000 - dense_3_accuracy: 1.0000 - dense_4_accuracy: 0.9999 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 1.0000 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 1.0000 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 1.0000 - val_loss: 3226.0668 - val_dense_1_loss: 322.6231 - val_dense_2_loss: 322.6032 - val_dense_3_loss: 322.6226 - val_dense_4_loss: 322.6193 - val_dense_5_loss: 322.6208 - val_dense_6_loss: 322.6336 - val_dense_7_loss: 322.6212 - val_dense_8_loss: 322.6371 - val_dense_9_loss: 322.6298 - val_dense_10_loss: 322.6516 - val_dense_1_accuracy: 0.9875 - val_dense_2_accuracy: 0.9875 - val_dense_3_accuracy: 0.9875 - val_dense_4_accuracy: 0.9875 - val_dense_5_accuracy: 0.9875 - val_dense_6_accuracy: 0.9875 - val_dense_7_accuracy: 0.9875 - val_dense_8_accuracy: 0.9862 - val_dense_9_accuracy: 0.9875 - val_dense_10_accuracy: 0.9875\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 575us/step - loss: 3229.7944 - dense_1_loss: 322.9793 - dense_2_loss: 322.9792 - dense_3_loss: 322.9794 - dense_4_loss: 322.9798 - dense_5_loss: 322.9793 - dense_6_loss: 322.9794 - dense_7_loss: 322.9795 - dense_8_loss: 322.9793 - dense_9_loss: 322.9794 - dense_10_loss: 322.9796 - dense_1_accuracy: 0.9999 - dense_2_accuracy: 0.9999 - dense_3_accuracy: 0.9998 - dense_4_accuracy: 0.9997 - dense_5_accuracy: 0.9999 - dense_6_accuracy: 0.9999 - dense_7_accuracy: 0.9999 - dense_8_accuracy: 0.9999 - dense_9_accuracy: 0.9999 - dense_10_accuracy: 0.9998 - val_loss: 3229.7748 - val_dense_1_loss: 322.9773 - val_dense_2_loss: 322.9773 - val_dense_3_loss: 322.9775 - val_dense_4_loss: 322.9774 - val_dense_5_loss: 322.9773 - val_dense_6_loss: 322.9774 - val_dense_7_loss: 322.9773 - val_dense_8_loss: 322.9776 - val_dense_9_loss: 322.9774 - val_dense_10_loss: 322.9775 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 580us/step - loss: 3229.8661 - dense_1_loss: 322.9872 - dense_2_loss: 322.9862 - dense_3_loss: 322.9868 - dense_4_loss: 322.9864 - dense_5_loss: 322.9861 - dense_6_loss: 322.9861 - dense_7_loss: 322.9860 - dense_8_loss: 322.9868 - dense_9_loss: 322.9860 - dense_10_loss: 322.9877 - dense_1_accuracy: 0.9992 - dense_2_accuracy: 0.9996 - dense_3_accuracy: 0.9992 - dense_4_accuracy: 0.9995 - dense_5_accuracy: 0.9998 - dense_6_accuracy: 0.9996 - dense_7_accuracy: 0.9996 - dense_8_accuracy: 0.9993 - dense_9_accuracy: 0.9997 - dense_10_accuracy: 0.9988 - val_loss: 3229.9122 - val_dense_1_loss: 322.9890 - val_dense_2_loss: 322.9884 - val_dense_3_loss: 322.9883 - val_dense_4_loss: 322.9883 - val_dense_5_loss: 322.9884 - val_dense_6_loss: 322.9880 - val_dense_7_loss: 322.9880 - val_dense_8_loss: 322.9874 - val_dense_9_loss: 322.9879 - val_dense_10_loss: 322.9886 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 589us/step - loss: 3229.8628 - dense_1_loss: 322.9865 - dense_2_loss: 322.9865 - dense_3_loss: 322.9865 - dense_4_loss: 322.9866 - dense_5_loss: 322.9863 - dense_6_loss: 322.9862 - dense_7_loss: 322.9862 - dense_8_loss: 322.9861 - dense_9_loss: 322.9861 - dense_10_loss: 322.9866 - dense_1_accuracy: 0.9998 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9999 - dense_4_accuracy: 0.9998 - dense_5_accuracy: 0.9999 - dense_6_accuracy: 0.9999 - dense_7_accuracy: 0.9999 - dense_8_accuracy: 0.9998 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 0.9997 - val_loss: 3229.8271 - val_dense_1_loss: 322.9815 - val_dense_2_loss: 322.9815 - val_dense_3_loss: 322.9815 - val_dense_4_loss: 322.9815 - val_dense_5_loss: 322.9815 - val_dense_6_loss: 322.9814 - val_dense_7_loss: 322.9814 - val_dense_8_loss: 322.9814 - val_dense_9_loss: 322.9814 - val_dense_10_loss: 322.9815 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 593us/step - loss: 3229.9772 - dense_1_loss: 322.9985 - dense_2_loss: 322.9975 - dense_3_loss: 322.9973 - dense_4_loss: 322.9971 - dense_5_loss: 322.9977 - dense_6_loss: 322.9970 - dense_7_loss: 322.9974 - dense_8_loss: 322.9979 - dense_9_loss: 322.9976 - dense_10_loss: 322.9988 - dense_1_accuracy: 0.9979 - dense_2_accuracy: 0.9984 - dense_3_accuracy: 0.9986 - dense_4_accuracy: 0.9985 - dense_5_accuracy: 0.9986 - dense_6_accuracy: 0.9987 - dense_7_accuracy: 0.9988 - dense_8_accuracy: 0.9983 - dense_9_accuracy: 0.9987 - dense_10_accuracy: 0.9976 - val_loss: 3229.8952 - val_dense_1_loss: 322.9865 - val_dense_2_loss: 322.9870 - val_dense_3_loss: 322.9866 - val_dense_4_loss: 322.9873 - val_dense_5_loss: 322.9872 - val_dense_6_loss: 322.9867 - val_dense_7_loss: 322.9868 - val_dense_8_loss: 322.9866 - val_dense_9_loss: 322.9870 - val_dense_10_loss: 322.9864 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 605us/step - loss: 3229.7998 - dense_1_loss: 322.9799 - dense_2_loss: 322.9803 - dense_3_loss: 322.9800 - dense_4_loss: 322.9802 - dense_5_loss: 322.9800 - dense_6_loss: 322.9800 - dense_7_loss: 322.9801 - dense_8_loss: 322.9803 - dense_9_loss: 322.9800 - dense_10_loss: 322.9800 - dense_1_accuracy: 0.9999 - dense_2_accuracy: 0.9999 - dense_3_accuracy: 0.9999 - dense_4_accuracy: 0.9999 - dense_5_accuracy: 0.9999 - dense_6_accuracy: 0.9999 - dense_7_accuracy: 0.9999 - dense_8_accuracy: 0.9999 - dense_9_accuracy: 0.9999 - dense_10_accuracy: 0.9999 - val_loss: 3230.1042 - val_dense_1_loss: 322.9995 - val_dense_2_loss: 323.0126 - val_dense_3_loss: 323.0008 - val_dense_4_loss: 322.9966 - val_dense_5_loss: 323.0105 - val_dense_6_loss: 323.0084 - val_dense_7_loss: 323.0047 - val_dense_8_loss: 323.0002 - val_dense_9_loss: 323.0016 - val_dense_10_loss: 322.9964 - val_dense_1_accuracy: 0.9937 - val_dense_2_accuracy: 0.9862 - val_dense_3_accuracy: 0.9931 - val_dense_4_accuracy: 0.9937 - val_dense_5_accuracy: 0.9869 - val_dense_6_accuracy: 0.9844 - val_dense_7_accuracy: 0.9887 - val_dense_8_accuracy: 0.9900 - val_dense_9_accuracy: 0.9937 - val_dense_10_accuracy: 0.9937\n",
            "Train on 10000 samples, validate on 1600 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 605us/step - loss: 3229.8133 - dense_1_loss: 322.9815 - dense_2_loss: 322.9814 - dense_3_loss: 322.9813 - dense_4_loss: 322.9814 - dense_5_loss: 322.9814 - dense_6_loss: 322.9813 - dense_7_loss: 322.9813 - dense_8_loss: 322.9814 - dense_9_loss: 322.9813 - dense_10_loss: 322.9812 - dense_1_accuracy: 1.0000 - dense_2_accuracy: 1.0000 - dense_3_accuracy: 1.0000 - dense_4_accuracy: 1.0000 - dense_5_accuracy: 1.0000 - dense_6_accuracy: 1.0000 - dense_7_accuracy: 1.0000 - dense_8_accuracy: 1.0000 - dense_9_accuracy: 1.0000 - dense_10_accuracy: 1.0000 - val_loss: 3229.9045 - val_dense_1_loss: 322.9871 - val_dense_2_loss: 322.9875 - val_dense_3_loss: 322.9872 - val_dense_4_loss: 322.9883 - val_dense_5_loss: 322.9877 - val_dense_6_loss: 322.9871 - val_dense_7_loss: 322.9874 - val_dense_8_loss: 322.9887 - val_dense_9_loss: 322.9873 - val_dense_10_loss: 322.9869 - val_dense_1_accuracy: 1.0000 - val_dense_2_accuracy: 1.0000 - val_dense_3_accuracy: 1.0000 - val_dense_4_accuracy: 1.0000 - val_dense_5_accuracy: 1.0000 - val_dense_6_accuracy: 1.0000 - val_dense_7_accuracy: 1.0000 - val_dense_8_accuracy: 1.0000 - val_dense_9_accuracy: 1.0000 - val_dense_10_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [17:41<00:00, 530.80s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AA0fKUA0rnw"
      },
      "source": [
        "anchor_,positive_,negative_,anchor_test, positive_test, negative_test,y_train_,y_val_ = [],[],[],[],[],[],[],[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMivLI5P-amb"
      },
      "source": [
        "# for i in range(11):\n",
        "#     model.layers[3].layers[i].trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gryS_l9O_urf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUCGywJt5O8k"
      },
      "source": [
        "anchor_,positive_,negative_,y_train_ =[],[],[],[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iwU5MCp_xxC"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"trimtl_modelusfinalall.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"trimtl_weightsusfinalall.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}